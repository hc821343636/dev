<style>
h1 {font-size: 2.5rem;}
h2 {font-size: 2rem;}
h3 {font-size: 1.8rem;}
p {font-size: 1.5rem;}
 ol, li {font-size: 1.5rem;} /* 设置有序列表和列表项的字体大小 */
</style>
# 1. 为什么要消息队列？
## 异步处理
一个经典却没有标准答案的问题：如何设计一个秒杀系统？

核心问题是：如何利用有限的服务器资源，尽可能多地处理短时间内的海量请求。

一个秒杀系统，有很多步骤：
- 风险控制
- 库存锁定
- 生成订单
- 短信通知
- 更新统计数据
只要用户秒杀请求通过风险控制、库存锁定就认为秒杀成功了。
![alt text](9d5618b819463753dbb22f7be6ce6b22.png)

处理一个秒杀请求，从 5 个步骤减少为 2 个步骤，这样不仅响应速度更快，并且在秒杀期间，我们可以把大量的服务器资源用来处理秒杀请求。秒杀结束后再把资源用于处理后面的步骤（异步），充分利用有限的服务器资源处理更多的秒杀请求。

## 流量控制
面临一个问题：如何避免过多的请求压垮我们的秒杀系统？

设计思路是：使用消息队列隔离网关和后端服务，以达到流量控制和保护后端服务的目的。

加入消息队列后，整个秒杀流程变为：
网关在收到请求后，将请求放入请求消息队列
；
后端服务从请求消息队列中获取 APP 请求，完成后续秒杀处理过程，然后返回结果。

![alt text](0e27ea38e7069be790e7d1fee14dc85b.png)

避免短时间大量秒杀请求到达后端，而是先存放到消息队列，然后后端再以自己的最大处理能力，消费消息队列的请求。

对于超时的请求可以直接丢弃，APP 将超时无响应的请求处理为秒杀失败即可。

但这样做同样是有代价的：
- 增加了系统调用链环节，导致总体的响应时延变长。
- 上下游系统都要将同步调用改为异步消息，增加了系统的复杂度。


一个更简单的方法：
如果我们可以估计出秒杀服务的处理能力，就可以同消息队列实现一个令牌桶，实现更简单的流量控制。
![alt text](539d6a4bff28c3901866a168f8d5e4d6.png)
如果令牌队列满了就丢弃令牌，如果网关获取（消费）令牌成功就向调用秒杀服务，否则就返回秒杀失败。

## 服务解耦

电商系统中比较核心的数据，当一个新订单创建时：

支付系统需要发起支付流程；

风控系统需要审核订单的合法性；

客服系统需要给用户发短信告知用户；

经营分析系统需要更新统计数据；

这些订单下游的系统都需要实时获得订单数据。随着业务不断发展，这些订单下游系统不断的增加，不断变化，并且每个系统可能只需要订单数据的一个子集，负责订单服务的开发团队不得不花费很大的精力，应对不断增加变化的下游系统，不停地修改调试订单系统与这些下游系统的接口。任何一个下游系统接口变更，都需要订单模块重新进行一次上线，对于一个电商的核心服务来说，这几乎是不可接受的。

所有的电商都选择用消息队列来解决类似的系统耦合过于紧密的问题。引入消息队列后，订单服务在订单变化时发送一条消息到消息队列的一个主题 Order 中，所有下游系统都订阅主题，这样每个下游系统都可以获得一份实时完整的订单数据。

## 缺陷
- 带来的延迟问题
- 增加了系统复杂性
- 可能产生数据不一致问题


# 2. 可供选择的消息队列
1. RabbtiMQ:  
小众，Erlang语言编写。开箱即用的消息队列，支持非常灵活的路由配置，和其他消息队列不同的是，它在生产者（Producer）和队列（Queue）之间增加了一个 Exchange 模块，理解为交换机。  
但RabbitMQ 对消息堆积的支持并不好；RabbitMQ 的性能最差，每秒钟可以处理几万到十几万条消息；
RabbitMQ 做一些扩展和二次开发比较困难。
 
2. RocketMQ：    
对在线业务的响应时延做了很多的优化，大多数情况下可以做到毫秒级的响应，如果你的应用场景很在意响应时延，那应该选择使用 RocketMQ。  
作为国产的消息队列，相比国外的比较流行的同类产品，在国际上还没有那么流行，与周边生态系统的集成和兼容程度要略逊一筹。

3. Kafka:  
Kafka 与周边生态系统的兼容性是最好的没有之一，尤其在大数据和流计算领域,Kafka 使用 Scala 和 Java 语言开发，设计上大量使用了**批量和异步**的思想，这种设计使得 Kafka 能做到超高的性能。Kafka 的性能，尤其是异步收发的性能，是三者中最好的，与 RocketMQ 并没有量级上的差异，大约每秒钟可以处理几十万条消息.  
异步批量的设计带来的问题是，它的同步收发消息的响应时延比较高，因为当客户端发送一条消息的时候，Kafka 并不会立即发送出去，而是要等一会儿攒一批再发送，在它的 Broker 中，很多地方都会使用这种“先攒一波再一起处理”的设计。当你的业务场景中，每秒钟消息数量没有那么多的时候，Kafka 的时延反而会比较高。所以，Kafka 不太适合**在线业务**场景。



RabbitMQ 采用的是队列模型，但是它一样可以实现发布 - 订阅的功能.
![alt text](ae4b954750fb39291db52d8b35e4531a.png)
RocketMQ 和 Kafka 采用的是发布 - 订阅模型，并且二者的消息模型是基本一致的。
![alt text](28bb671c97b6e19013d4a16ab8f83448.png)

# 3. 消息队列如何实现分布式事务

Kafka和RocketMQ都提供了事务相关功能

一个需求：
在订单库中插入一条订单数据，创建订单；
发消息给消息队列，消息的内容就是刚刚创建的订单。
购物车系统订阅相应的主题，接收订单创建的消息，然后清理购物车，在购物车中删除订单中的商品。

![alt text](d8b56994f6f49e8b808955ec3d61a5cc.png)

半消息和普通消息的唯一区别是，在事务提交之前，对于消费者来说，这个消息是不可见的。

如果在第四步失败了：  
Kafka：抛出异常  
RocketMQ：事务反查机制————如果 Producer （订单系统），在提交或者回滚事务消息时发生网络异常，RocketMQ 的 Broker 没有收到提交或者回滚的请求，Broker 会定期去 Producer 上反查这个事务对应的本地事务的状态，然后根据反查结果决定提交或者回滚这个事务。
![alt text](ab9bb2c9f2a2ef536278567bf0d5f3eb.png)

# 4. 如何保证消息不丢失

## 检测丢失方法
利用有序性解决：给Producer端，每次发送消息附加一个连续递增的序号，然后于Consumer端检查序号的连续性（对于Kafka和RocketMQ只保证分区上的消息是有序的）。

## 保证消息可靠传递
![alt text](480ab0224443d94d4461212583f2d207.png) 

- 生产阶段：只要 Producer 收到了 Broker 的确认响应，就可以保证消息在生产阶段不会丢失。超时就重发，需注意重发间隔。

- 储存阶段：如果 Broker 出现了故障，比如进程死掉了或者服务器宕机了，可能会丢失消息。  
    1. 对于单个节点的 Broker，需要配置 Broker 参数，在收到消息后，将消息写入磁盘后再给 Producer 返回确认响应，这样即使发生宕机，由于消息已经被写入磁盘，就不会丢失消息，恢复后还可以继续消费。

    2. Broker 是由多个节点组成的集群，需要将 Broker 集群配置成：至少将消息发送到 2 个以上的节点，再给客户端回复发送确认响应。通过要求至少2个副本确认，可以容忍一个副本的故障。

- 消费阶段：采用和生产阶段类似的确认机制来保证消息的可靠性。
客户端从 Broker 拉取消息后，执行用户的消费业务逻辑，成功后，才会给 Broker 发送消费确认响应。如果 Broker 没有收到消费确认响应，下次拉消息的时候还会返回同一条消息，确保消息不会在网络传输过程中丢失，也不会因为客户端在执行消费逻辑中出错导致丢失。  
不要在收到消息后就立即发送消费确认，而是应该在**执行完所有消费业务逻辑**之后，再发送消费确认。

# 5. 如何处理重复消息？

如果producer在发送消息时，由消息队列接收后，返回的ack丢失了，超时重发，导致消息队列收到了重复的消息。

MQTT协议中，三种服务质量：  

- At most once: 至多一次。消息在传递时，最多会被送达一次。换一个说法就是，没什么消息可靠性保证，允许丢消息。一般都是一些对消息可靠性要求不太高的监控场景使用，比如每分钟上报一次机房温度数据，可以接受数据少量丢失。

- At least once: 至少一次。消息在传递时，至少会被送达一次。也就是说，不允许丢消息，但是允许有少量重复消息出现。（绝大多数采用）

- Exactly once：恰好一次。消息在传递时，只会被送达一次，不允许丢失也不允许重复，这个是最高的等级。”

## 使用幂等性解决重复消息
数学语言：如果一个函数 f(x) 满足：f(f(x)) = f(x)，则函数 f(x) 满足幂等性。  
翻译为白话：即其任意多次执行所产生的影响均与一次执行的影响相同。

对于系统：At least once + 幂等消费 = Exactly once。 

1. 利用数据库唯一约束实现幂等性。  
eg.将账户 X 的余额加 100 元。  
建一张转账流水表，这个表有三个字段：转账单 ID、账户 ID 和变更金额，然后给转账单 ID 和账户 ID 这两个字段联合起来创建一个唯一约束，这样对于相同的转账单 ID 和账户 ID，表里至多只能存在一条记录。  
数据库中：INSERT IF NOT EXIST”语义的存储类系统都可以用于实现幂等；可以用 Redis 的 SETNX 命令来替代数据库中的唯一约束。

2. 为更新的数据加入前置条件（乐观锁）
给数据加版本号，如果当前版本号不是消息中版本号那么就拒绝更新数据，否则就更新，然后版本号加1.

3. 记录并检查操作 （Token 机制或者 GUID（全局唯一 ID）机制） 
在执行数据更新操作之前，先检查一下是否执行过这个更新操作：在发送消息时，给每条消息指定一个全局唯一的 ID，消费时，先根据这个 ID 检查这条消息是否有被消费过，如果没有消费过，才更新数据，然后将消费状态置为已消费。














 





