
<style>
h1 {font-size: 2.5rem;}
h2 {font-size: 2rem;}
h3 {font-size: 1.8rem;}
p {font-size: 1.5rem;}
 ol, li {font-size: 1.5rem;} /* 设置有序列表和列表项的字体大小 */
</style>
# 概念
- Hadoop是一个分布式存储和计算框架，包含HDFS和MapReduce。

- MapReduce是Hadoop的核心计算引擎，适用于批处理任务。 **面向过程的大数据计算 。**  
我们在用MapReduce 编程的时候，思考的是，如何将计算逻辑用 Map 和 Reduce 两个阶段实现，map 和 reduce 函数的输入和输出是什么，

- Spark是一个快速、通用的大数据处理引擎，支持内存计算，提供比MapReduce更高的性能和更丰富的API。**面向对象的大数据计算**。  
而Spark则直接针对**数据进行编程**，将大规模数据集合抽象成一个RDD对象，然后在这个RDD上进行各种计算处理，得到一个新的 RDD，继续计算处理，直到得到最后的结果数据。所以 Spark可以理解成是面向对象的大数据计算。我们在进行Spark编程的时候，思考的是一个RDD对象需要经过什么样的操作，转换成另一个RDD 对象，思考的重心和落脚点都在RDD上。

1. Hadoop vs Spark：

存储：Hadoop主要依赖HDFS进行分布式存储，而Spark可以使用HDFS、S3等多种存储系统。
计算：Hadoop主要依赖MapReduce进行分布式计算，而Spark则使用内存计算引擎，提供更高的计算性能。
生态系统：Hadoop有一个完整的大数据处理生态系统，而Spark则提供了丰富的API和多种计算模式，适应更广泛的应用场景。

2. MapReduce vs Spark：

计算模式：MapReduce适用于批处理任务，而Spark不仅支持批处理，还支持流处理、机器学习和图计算。
性能：由于内存计算的优势，Spark的处理速度通常比MapReduce快10-100倍。
编程复杂度：Spark提供了更高层次的API，简化了编程复杂度，而MapReduce编程模型相对较为复杂。